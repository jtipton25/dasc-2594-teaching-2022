---
title: "Teaching Multivariable Math in DASC 2594"
subtitle: ""
author: "John Tipton"
institute: "The University of Arkansas"
date: "2022/06/01 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    self_contained: true
    lib_dir: libs
    nature:
      navigation:
        scroll: false      
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
urlcolor: blue
knit: pagedown::chrome_print
---

```{css, echo = FALSE}
.remark-slide-content {
  font-size: 18px;
  padding: 20px 80px 20px 80px;
}
.remark-code, .remark-inline-code {
  background: #f0f0f0;
}
.remark-code {
  font-size: 14px;
}
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.very-large .remark-code { /*Change made here*/
  font-size: 150% !important;
}
.large .remark-code { /*Change made here*/
  font-size: 125% !important;
}
.small .remark-code { /*Change made here*/
  font-size: 75% !important;
}

.very-small .remark-code { /*Change made here*/
  font-size: 50% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 40% !important;
}
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
```

# Materials

* Available on gitHub at [https://github.com/jtipton25/dasc-2594-teaching-2022](https://github.com/jtipton25/dasc-2594-teaching-2022) 

* Lecture notes at [https://jtipton25.github.io/multivariable-math/](https://jtipton25.github.io/multivariable-math/)

---

# Guiding principles

* Teach the fundamental multivariable math needed for data science

* Focus on the math and concepts, leave the computation to the computer

* Focus on the key ideas needed for data science from linear algebra and (multivariable) calculus III 
    * Matrix and vector operations
    * Solving systems of equations
    * Understanding rank and invertibility
    * Matrix factorizations
    * Gradients

* Omit topics in traditional multivariable calculus courses
    * cross-products
    * line integrals
    * multiple integration over irregular boundaries
    * vector fields

---

# Fundamental concepts

* Matrix operations (multiplication, addition)    

* Solving systems of linear equations

    * Applying this to least squares problems (linear regression)

* Demonstrating concepts like rank through data-science applications

    * Fitting models with basis expansions

* Applying calculus to optimization/gradient descent problems


---

# Learning Evaluation

* Goal: Make this a challenging but applicable course

* Homeworks (traditional paper and pencil problems)

* Labs (application using programming)

* Exams (In class and take home)


---

# Continuous Improvement

* Students actually wanted more, smaller exams

* Homeworks and labs were challenging, make these more approachable

* Onboarding students (freshman) with that are Cal III ready but don't have programming experience

* Developing mini-problems and quizzes for more, but lower stakes, practice

    * e.g., how many pivot columns, what is the rank, multiply these matrices, etc.
    
    
---

# Getting started with matrices

---

# Examples (Elementary Operations)

```{r}
library(dasc2594)
A <- matrix(1:9, 3, 3)
print(array_to_latex(A))
```


Can display the matrix (in Rmarkdown) with 

```
$`r array_to_latex(A)`$
```

to get

$`r array_to_latex(A)`$

```{r}
# using dasc2594
rref(A)
```

---


# Examples (Elementary Operations)


* Add 2 times row 2 to row 3 of `A` and save as `B`

```{r}
B <- A
B[3, ] <- 2 * A[2, ] + A[3, ]
B
```

* Normalize row 2 of `A` and save as `C`

```{r}
C <- A
C[2, ] <- C[2, ] / C[2, 1]
C
```

---

# Examples (Elementary Operations)

* Swap columns 2 and 3 in the matrix `A` and save as `B`

```{r}
B <- A[, c(1, 3, 2)]
B
```

* Normalize row 2 of `A` and save as `C`

```{r}
C <- A
C[2, ] <- C[2, ] / C[2, 1]
C
```

---

# Examples (Elementary Operations)

* After some practice (1-2 labs) have them write

```{r}
# zero out first column in second row
A[2, ] <- A[2, ] - 2 * A[1, ]
# zero out first column in third row
A[3, ] <- A[3, ] - 3 * A[1, ]
# normalize leading column in second row
A[2, ] <- A[2, ] / (-3)
# normalize leading column in third row
A[3, ] <- A[3, ] / (-6)
# zero out second column in first row
A[1, ] <- A[1, ] - 4 * A[3, ]
# zero out second column in third row
A[3, ] <- A[3, ] - A[2, ]
```

---

# Examples (Elementary Operations)

* Have them do row operations, then they write functions that do the elementary row operations

* Add 2 times row 2 to row 3 of `A` and save as `B`

```{r}
A <- matrix(1:9, 3, 3)
add_rows <- function(A, row_1, row_2, a) {
  A[row_1] <- A[row_1] + a * A[row_2]
  return(A)
}

add_rows(A, row_1 = 3, row_2 = 3, a = 2)
```

---

# Examples (Elementary Operations)

* Can add in error checking (for more practice and students more experienced programming)

```{r, error = TRUE}
add_rows <- function(A, row_1, row_2, a) {
  if ((row_1 < 1) | row_1 > nrow(A)) {
    stop("row_1 must be a valid row")
  }
  A[row_1] <- A[row_1] + a * A[row_2]
  return(A)
}
add_rows(A, row_1 = 4, row_2 = 3, a = 2)
```

---







# Examples (RREF)


* Using the [matlib](http://friendly.github.io/matlib/) R package

.small[
```{r}
library(matlib)
gaussianElimination(A, verbose=TRUE)
```
]

---

# Examples

* By "hand" 

```{r}
# zero out first column in second row
A[2, ] <- A[2, ] - 2 * A[1, ]
# zero out first column in third row
A[3, ] <- A[3, ] - 3 * A[1, ]
# normalize leading column in second row
A[2, ] <- A[2, ] / (-3)
# normalize leading column in third row
A[3, ] <- A[3, ] / (-6)
# zero out second column in first row
A[1, ] <- A[1, ] - 4 * A[3, ]
# zero out second column in third row
A[3, ] <- A[3, ] - A[2, ]
```


* Can use functions that do the elementary row operations, then use functions from `dasc2594` or `matlib` libraries.

* I really don't care that they can do RREF by hand.

---

# Examples (Matrix multiplication)

* Multiply using rows and columns

.pull-left[
```{r}
A <- matrix(1:9, 3, 3)
A
r1 <- A[1, ]
r2 <- A[2, ]
r3 <- A[3, ]
```
]

.pull-right[
```{r}
B <- matrix(1:3, 3, 3)
B
c1 <- B[, 1]
c2 <- B[, 2]
c3 <- B[, 3]
```
]

---

# Examples (Matrix multiplication)

* Multiply using rows and columns

```{r}
# initialize a matrix
AB <- matrix(0, 3, 3)
AB[1, 1] <- r1 %*% c1 # or A[1, 1] <- sum(r1 * c1)
AB[1, 2] <- r1 %*% c2 # or A[1, 2] <- sum(r1 * c2)
AB[1, 3] <- r1 %*% c3 # or A[1, 3] <- sum(r1 * c3)
AB[2, 1] <- r2 %*% c1 # or A[2, 1] <- sum(r2 * c1)
AB[2, 2] <- r2 %*% c2 # or A[2, 2] <- sum(r2 * c2)
AB[2, 3] <- r2 %*% c3 # or A[2, 3] <- sum(r2 * c3)
AB[3, 1] <- r3 %*% c1 # or A[3, 1] <- sum(r3 * c1)
AB[3, 2] <- r3 %*% c2 # or A[3, 2] <- sum(r3 * c2)
AB[3, 3] <- r3 %*% c3 # or A[3, 3] <- sum(r3 * c3)

AB
```


```{r}
A %*% B
```


---

# Examples (Matrix multiplication)

* Multiply using for loop

```{r}
AB <- matrix(0, nrow(A), ncol(B))
for (i in 1:nrow(A)) {
  for (j in 1:ncol(B)) {
    AB[i, j] <- sum(A[i, ] * B[, j])
  }
}

all.equal(AB, A %*% B)
```


---

# Example (Matrix multiplication complexity)

* Some basic introduction to $O(\cdot)$ notation and benchmarking code

```{r, cache = TRUE}
library(microbenchmark)
# takes a few seconds
n <- c(5, 10, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 750, 1000)
multiply_matrices <- function(n) {
  # generate n x n matrices
  A <- matrix(rnorm(n^2), n, n)
  B <- matrix(rnorm(n^2), n, n)
  A %*% B
}

# timings
timings <- rep(0, length(n))
for (i in 1:length(n)) {
  # create the benchmarking object with 20 replicates
  bm <- microbenchmark(multiply_matrices(n[i]), times = 20)
  # calculate the time
  timings[i] <- mean(bm$time)
}
```


---

# Example (Matrix multiplication complexity)

* Matrix multiplication is $O(n^3)$ for multiplication of $n \times n$ matrices

```{r, fig.width = 6, fig.height = 4, fig.align = 'center', message = FALSE}
data.frame(timings, n) %>%
  ggplot(aes(x = n, y = timings)) +
  geom_point() +
  stat_smooth(method = "lm", color = "blue", se = FALSE) +
  stat_smooth(method = "lm", color = "red", formula = y ~ poly(x, 2), se = FALSE) +
  stat_smooth(method = "lm", color = "orange", formula = y ~ poly(x, 3), se = FALSE) +
  ggtitle("Matrix Multiply")
```


---

# Solving systems of equations

